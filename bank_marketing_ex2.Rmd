---
title: "bank_marketin_ex2"
author: "*Buthaina Alshareef*"
date: "*01-12-2020*"
output:
  html_document:
   toc: true
   toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Packages required
library(rsample)
library(caret)
library(tidyverse)
library(inspectdf) 
library(ISLR)
library(dplyr)
library(ggplot2)
library(recipes)
library(psych)

# Model interpretability packages
library(vip)       # variable importance
library(ROCR)      # ROC curve
```


```{r}
#http://archive.ics.uci.edu/ml/datasets/Bank+Marketing

#read the data set
bank <- read.csv2("data/bank-additional-full.csv", dec = ".")
```

convert all characters to factors
```{r}
bank[sapply(bank, is.character)] <- lapply(bank[sapply(bank, is.character)], 
                                       as.factor)
```

drop duration and nr.employed columns 
```{r}
bank <- select(bank, c (-duration, - nr.employed))
```

take 70% train set to check if the training method works well
```{r}
set.seed(123) # for reproducibility
split <- initial_split(bank, strata = "y", prop = 0.7)
train <- training(split)

```



Create and a apply a blueprint of feature engineering processes that you think will help your model improve.
```{r}
blueprint <- recipe(y ~ ., data = train) %>%
  step_nzv(all_nominal()) %>%
  step_center(all_numeric(), -all_outcomes()) %>%
  step_scale(all_numeric(), -all_outcomes()) %>%
   step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE) %>% 
   step_pca(all_numeric(), -all_outcomes())
  #step_integer(all_nominal()) %>%
```


#Portfolio Builder Exercise 2

##1
Depending on the type of response variable, apply a linear or logistic regression model.

First, apply the model to your data without pre-applying feature engineering processes.

```{r, cache=TRUE}
set.seed(123)
(preBp_model <- train(
  y ~ ., 
  data = train, 
  method = "glm",
  family = "binomial",
  trControl = trainControl(method = "cv", number = 10)
))

```


Now reapply the model to your data that has feature engineered.(blueprint/ preprocess?)
```{r}
set.seed(123)
(Bp_model <- train(
  blueprint, 
  data = train, 
  method = "glm",
  family = "binomial",
  trControl = trainControl(method = "cv", number = 10)
))


```


Did your model performance improve?
yes from 0.9004575 to 0.8953244 




##2
- Apply a principal component regression model.
   it is not applicable for classification tasks!


##3
- Apply a partial least squares regression model.
    it is not applicable for classification tasks!


##4

- Apply a regularized regression model.
   it is not applicable for classification tasks!

```{r}
#save.image("myWorkspace_ex2.rds")
```


```{r}
#load("myWorkspace_ex2.rds")
```



